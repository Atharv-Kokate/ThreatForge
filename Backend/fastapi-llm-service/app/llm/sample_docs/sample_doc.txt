This document provides a brief overview of secure design patterns for AI/ML systems and common vulnerabilities to watch for.

Authentication & Authorization
- Use strong authentication (OAuth2 / OIDC) for user-facing systems.
- Prefer short-lived access tokens and rotate keys; validate scopes on every API call.

Data Handling & Privacy
- Classify data sources and mark sensitive fields (PII, PHI, credentials).
- Apply input sanitization and output masking before storing or sending to models.

Model & Prompt Security
- Apply prompt guardrails to prevent prompt injection and leakage of sensitive data.
- Limit model exposure by filtering or redacting user-supplied content where applicable.

Infrastructure & Monitoring
- Enforce least-privilege IAM for model and data storage access.
- Implement anomaly detection and logging for unusual model queries or high-cost patterns.

Provenance & Auditing
- Keep provenance for external data and web-sourced evidence (URL, title, snippet).
- Store high-level summaries in the primary DB and archive raw model outputs separately when needed.

This sample document is intentionally short; ingest it to test RAG retrieval and provenance features.
